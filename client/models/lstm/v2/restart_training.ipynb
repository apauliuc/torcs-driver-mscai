{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "\n",
    "from model import LSTMDriver\n",
    "from model import HYPERPARAMS\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='retraining.log',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_ROOT = '../../../..'\n",
    "LEARNED_DRIVER = 'snakeoil_miner/data'\n",
    "DIFFICULTY = 'easy'\n",
    "\n",
    "\n",
    "TRAINING_FILES = glob.glob('/'.join([PROJECT_ROOT, LEARNED_DRIVER, DIFFICULTY, '*.csv']))\n",
    "TRAINING_DATA = {}\n",
    "for FILE in TRAINING_FILES:\n",
    "    DF = pd.read_csv(FILE, index_col=False)\n",
    "    TRAINING_DATA[FILE] = DF.values\n",
    "\n",
    "VALIDATION_FILES = glob.glob('/'.join([PROJECT_ROOT, LEARNED_DRIVER, 'validation', '*.csv']))\n",
    "VALIDATION_DATA = {}\n",
    "for FILE in VALIDATION_FILES:\n",
    "    DF = pd.read_csv(FILE, index_col=False)\n",
    "    VALIDATION_DATA[FILE] = DF.values\n",
    "    \n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    DTYPE = torch.cuda.FloatTensor\n",
    "else:\n",
    "    DTYPE = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filepath='latest_checkpoint.pth.tar'):\n",
    "    torch.save(state, 'checkpoints/' + filepath)\n",
    "    if is_best:\n",
    "        torch.save(state, 'checkpoints/best_checkpoint.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(training_data, model, criterion, optimzier):\n",
    "    loss = 0\n",
    "    model.train(mode=True)\n",
    "    for key in training_data:\n",
    "        logging.info('--- Parsing track {}-{}'.format(key.split('/')[-2], key.split('/')[-1]))\n",
    "        print('--- Parsing track {}-{}'.format(key.split('/')[-2], key.split('/')[-1]))\n",
    "        \n",
    "        model.hidden_state = model.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        track_sequence = training_data[key]\n",
    "\n",
    "        targets = track_sequence[:, 0:3]\n",
    "        inputs = track_sequence[:, 3:]\n",
    "\n",
    "        targets_variable = autograd.Variable(torch.Tensor(targets)).type(DTYPE)\n",
    "        inputs_variable = autograd.Variable(torch.Tensor(inputs),  requires_grad=True).type(DTYPE)\n",
    "\n",
    "        outputs_variable = model(inputs_variable)\n",
    "\n",
    "        track_loss = criterion(outputs_variable, targets_variable)\n",
    "\n",
    "        track_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += track_loss.data[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(validation_data, model, criterion):\n",
    "    loss = 0\n",
    "    model.train(mode=False)\n",
    "    for key in validation_data:\n",
    "        logging.info('--- Parsing track {}-{}'.format(key.split('/')[-2], key.split('/')[-1]))\n",
    "        print('--- Parsing track {}-{}'.format(key.split('/')[-2], key.split('/')[-1]))\n",
    "        \n",
    "        model.hidden_state = model.init_hidden()\n",
    "        track_sequence = validation_data[key]\n",
    "\n",
    "        targets = track_sequence[:, 0:3]\n",
    "        inputs = track_sequence[:, 3:]\n",
    "\n",
    "        targets_variable = autograd.Variable(torch.Tensor(targets), volatile=True).type(DTYPE)\n",
    "        inputs_variable = autograd.Variable(torch.Tensor(inputs), volatile=True).type(DTYPE)\n",
    "\n",
    "        outputs_variable = model(inputs_variable)\n",
    "\n",
    "        track_loss = criterion(outputs_variable, targets_variable)\n",
    "\n",
    "        loss += track_loss.data[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.132554\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.159332\n",
      "-------------------------------------------------------\n",
      "Epoch [2/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.133571\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.143519\n",
      "-------------------------------------------------------\n",
      "Epoch [3/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.120733\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.149055\n",
      "-------------------------------------------------------\n",
      "Epoch [4/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.115905\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.145949\n",
      "-------------------------------------------------------\n",
      "Epoch [5/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.111030\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.141099\n",
      "-------------------------------------------------------\n",
      "Epoch [6/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.107495\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.136149\n",
      "-------------------------------------------------------\n",
      "Epoch [7/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.108918\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.144497\n",
      "-------------------------------------------------------\n",
      "Epoch [8/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.111568\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.137110\n",
      "-------------------------------------------------------\n",
      "Epoch [9/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.114763\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.149441\n",
      "-------------------------------------------------------\n",
      "Epoch [10/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.133175\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.159751\n",
      "-------------------------------------------------------\n",
      "Epoch [11/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.114628\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.146547\n",
      "-------------------------------------------------------\n",
      "Epoch [12/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.112531\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.147613\n",
      "-------------------------------------------------------\n",
      "Epoch [13/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.109627\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.137932\n",
      "-------------------------------------------------------\n",
      "Epoch [14/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.104837\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.139310\n",
      "-------------------------------------------------------\n",
      "Epoch [15/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.101936\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.141106\n",
      "-------------------------------------------------------\n",
      "Epoch [16/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.099257\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.135944\n",
      "-------------------------------------------------------\n",
      "Epoch [17/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.096900\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.134541\n",
      "--- --- best model found so far: 0.134541\n",
      "-------------------------------------------------------\n",
      "Epoch [18/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.095136\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.136137\n",
      "-------------------------------------------------------\n",
      "Epoch [19/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.095522\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.133887\n",
      "--- --- best model found so far: 0.133887\n",
      "-------------------------------------------------------\n",
      "Epoch [20/150]\n",
      "--- Parsing track easy-race_03.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.097481\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.138854\n",
      "-------------------------------------------------------\n",
      "Epoch [21/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.098477\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.136007\n",
      "-------------------------------------------------------\n",
      "Epoch [22/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.103396\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.150522\n",
      "-------------------------------------------------------\n",
      "Epoch [23/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.130192\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.139391\n",
      "-------------------------------------------------------\n",
      "Epoch [24/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.117236\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.144149\n",
      "-------------------------------------------------------\n",
      "Epoch [25/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.110805\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.153217\n",
      "-------------------------------------------------------\n",
      "Epoch [26/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.104632\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.139609\n",
      "-------------------------------------------------------\n",
      "Epoch [27/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.100945\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.137853\n",
      "-------------------------------------------------------\n",
      "Epoch [28/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.097644\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.137995\n",
      "-------------------------------------------------------\n",
      "Epoch [29/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.094167\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.133348\n",
      "--- --- best model found so far: 0.133348\n",
      "-------------------------------------------------------\n",
      "Epoch [30/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.095330\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.134927\n",
      "-------------------------------------------------------\n",
      "Epoch [31/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.096341\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.135265\n",
      "-------------------------------------------------------\n",
      "Epoch [32/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.103287\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.132297\n",
      "--- --- best model found so far: 0.132297\n",
      "-------------------------------------------------------\n",
      "Epoch [33/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.099366\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.132434\n",
      "-------------------------------------------------------\n",
      "Epoch [34/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.093880\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.138769\n",
      "-------------------------------------------------------\n",
      "Epoch [35/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.091813\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.128201\n",
      "--- --- best model found so far: 0.128201\n",
      "-------------------------------------------------------\n",
      "Epoch [36/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.088493\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.129913\n",
      "-------------------------------------------------------\n",
      "Epoch [37/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.087774\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.134000\n",
      "-------------------------------------------------------\n",
      "Epoch [38/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.086652\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VALIDATION LOSS: 0.136048\n",
      "-------------------------------------------------------\n",
      "Epoch [39/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.085131\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.130894\n",
      "-------------------------------------------------------\n",
      "Epoch [40/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.083179\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.135345\n",
      "-------------------------------------------------------\n",
      "Epoch [41/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.083607\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n",
      "--- Parsing track validation-race_30.csv\n",
      "--- VALIDATION LOSS: 0.134084\n",
      "-------------------------------------------------------\n",
      "Epoch [42/150]\n",
      "--- Parsing track easy-race_03.csv\n",
      "--- Parsing track easy-race_00.csv\n",
      "--- Parsing track easy-race_01.csv\n",
      "--- Parsing track easy-race_02.csv\n",
      "--- TRAINING LOSS: 0.082493\n",
      "--- Parsing track validation-race_31.csv\n",
      "--- Parsing track validation-race_33.csv\n",
      "--- Parsing track validation-race_32.csv\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('checkpoints/latest_checkpoint.pth.tar')\n",
    "if CUDA:\n",
    "    model = LSTMDriver(HYPERPARAMS.INPUT_SIZE,\n",
    "                       HYPERPARAMS.LSTM_HIDDEN_SIZE,\n",
    "                       HYPERPARAMS.HIDDEN_LAYER_SIZE,\n",
    "                       HYPERPARAMS.DROPOUT_PROB,\n",
    "                       HYPERPARAMS.NUM_LAYERS,\n",
    "                       HYPERPARAMS.TARGET_SIZE,\n",
    "                       HYPERPARAMS.BATCH_SIZE).cuda()\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "else:\n",
    "    model = LSTMDriver(HYPERPARAMS.INPUT_SIZE,\n",
    "                       HYPERPARAMS.LSTM_HIDDEN_SIZE,\n",
    "                       HYPERPARAMS.HIDDEN_LAYER_SIZE,\n",
    "                       HYPERPARAMS.DROPOUT_PROB,\n",
    "                       HYPERPARAMS.NUM_LAYERS,\n",
    "                       HYPERPARAMS.TARGET_SIZE,\n",
    "                       HYPERPARAMS.BATCH_SIZE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=HYPERPARAMS.LEARNING_RATE)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', verbose=True)\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "min_loss = checkpoint['min_loss']\n",
    "losses = {\n",
    "  'training': [],\n",
    "  'validation': []\n",
    "}\n",
    "\n",
    "# for epoch in np.arange(checkpoint['epoch'], HYPERPARAMS.NUM_EPOCHS):\n",
    "for epoch in np.arange(50):\n",
    "    logging.info('Epoch [%d/%d]' %(epoch+1, HYPERPARAMS.NUM_EPOCHS))\n",
    "    print('Epoch [%d/%d]' %(epoch+1, HYPERPARAMS.NUM_EPOCHS))\n",
    "    \n",
    "    is_best = False\n",
    "\n",
    "    training_loss = train(TRAINING_DATA, model, criterion, optimizer)\n",
    "    logging.info('--- TRAINING LOSS: %f' % training_loss)\n",
    "    print('--- TRAINING LOSS: %f' % training_loss)\n",
    "\n",
    "    validation_loss = validate(VALIDATION_DATA, model, criterion)\n",
    "    logging.info('--- VALIDATION LOSS: %f' % validation_loss)\n",
    "    print('--- VALIDATION LOSS: %f' % validation_loss)\n",
    "\n",
    "    if validation_loss < min_loss:\n",
    "        logging.info('--- --- best model found so far: %f' % validation_loss)\n",
    "        print('--- --- best model found so far: %f' % validation_loss)\n",
    "        min_loss = validation_loss\n",
    "        is_best = True\n",
    "\n",
    "    losses['training'].append(training_loss)\n",
    "    losses['validation'].append(validation_loss)\n",
    "\n",
    "    save_checkpoint({\n",
    "          'epoch': epoch + 1,\n",
    "          'state_dict': model.state_dict(),\n",
    "          'min_loss': min_loss,\n",
    "          'optimizer' : optimizer.state_dict(),\n",
    "      }, is_best)\n",
    "\n",
    "    scheduler.step(validation_loss)\n",
    "    logging.info('-------------------------------------------------------')\n",
    "    print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
