{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_files = glob.glob('training_data/oval/*.csv')\n",
    "training_data = {}\n",
    "\n",
    "DATA = pd.DataFrame()\n",
    "for training_file in training_files:\n",
    "    df = pd.read_csv(training_file, index_col=False)\n",
    "    DATA = pd.concat([DATA, df])\n",
    "DATA_LENGTH = DATA.shape[0]\n",
    "for training_file in training_files:\n",
    "    df = pd.read_csv(training_file, index_col=False)\n",
    "    df_std = (df - DATA.mean()) / DATA.std()\n",
    "    for column in df_std:\n",
    "        df_std[column].fillna(df[column], inplace=True)\n",
    "    training_data[training_file] = df_std.values\n",
    "\n",
    "\n",
    "TARGET_SIZE = 3\n",
    "INPUT_SIZE = 22\n",
    "HIDDEN_SIZE = 22\n",
    "\n",
    "NUM_LAYERS = 1\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 50\n",
    "MILESTONES = [20, 30, 40]\n",
    "GAMMA = 0.1\n",
    "LEARNING_RATE = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filepath):\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        torch.save(state, 'best_model/best_model_full.pth.tar')\n",
    "        torch.save(state['state_dict'], 'best_model/best_model_state.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMDriver(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, batch_size):\n",
    "        super(LSTMDriver, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        super(LSTMDriver, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def init_hidden(self, hidden_state=None):\n",
    "        if hidden_state is None:\n",
    "            return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)),\n",
    "                    autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)))\n",
    "        else:\n",
    "            return (autograd.Variable(hidden_state[0].data), autograd.Variable(hidden_state[1].data))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, hidden_out = self.lstm(x.view(1, -1), self.hidden)\n",
    "        linear_out = self.linear(lstm_out)\n",
    "        self.hidden = (autograd.Variable(hidden_out[0].data), autograd.Variable(hidden_out[1].data))\n",
    "        \n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.127350\n",
      "-------------------------------------------------------\n",
      "Epoch [37/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.101507\n",
      "-------------------------------------------------------\n",
      "Epoch [38/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.097526\n",
      "-------------------------------------------------------\n",
      "Epoch [39/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.106203\n",
      "-------------------------------------------------------\n",
      "Epoch [40/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.114630\n",
      "-------------------------------------------------------\n",
      "Epoch [41/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.112435\n",
      "-------------------------------------------------------\n",
      "Epoch [42/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.111411\n",
      "-------------------------------------------------------\n",
      "Epoch [43/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.125640\n",
      "-------------------------------------------------------\n",
      "Epoch [44/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.124842\n",
      "-------------------------------------------------------\n",
      "Epoch [45/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.124819\n",
      "-------------------------------------------------------\n",
      "Epoch [46/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.123223\n",
      "-------------------------------------------------------\n",
      "Epoch [47/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.123187\n",
      "-------------------------------------------------------\n",
      "Epoch [48/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.122634\n",
      "-------------------------------------------------------\n",
      "Epoch [49/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.122234\n",
      "-------------------------------------------------------\n",
      "Epoch [50/50]\n",
      "--- parsing track: oval/race_CEYP.csv\n",
      "--- parsing track: oval/race_XIWR.csv\n",
      "--- parsing track: oval/race_LNJK.csv\n",
      "--- parsing track: oval/race_DNTY.csv\n",
      "--- parsing track: oval/race_XVQL.csv\n",
      "---|--- model is worse: 0.161095\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_checkpoints/checkpoint.pth.tar')\n",
    "\n",
    "model = LSTMDriver(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, TARGET_SIZE, BATCH_SIZE)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "losses = [checkpoint['min_loss']]\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA, last_epoch=checkpoint['epoch']-1)\n",
    "\n",
    "min_loss = checkpoint['min_loss']\n",
    "\n",
    "for epoch in np.arange(checkpoint['epoch'] - 1, NUM_EPOCHS):\n",
    "    print('Epoch [%d/%d]' %(epoch+1, NUM_EPOCHS))\n",
    "    \n",
    "    current_loss = 0\n",
    "    is_best = False\n",
    "    scheduler.step()\n",
    "    for key in training_data:\n",
    "        print('--- parsing track: %s/%s' % (key.split('/')[1], key.split('/')[2]))\n",
    "\n",
    "        model.init_hidden()\n",
    "        track_data = training_data[key]\n",
    "        for row in track_data:\n",
    "            optimizer.zero_grad()\n",
    "            targets = row[0:3]\n",
    "            inputs = row[3:]\n",
    "\n",
    "            targets_variable = autograd.Variable(torch.Tensor(targets))\n",
    "            inputs_variable = autograd.Variable(torch.Tensor(inputs))\n",
    "\n",
    "            outputs_variable = model(inputs_variable)\n",
    "            loss = criterion(outputs_variable, targets_variable)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            current_loss += loss.data[0]\n",
    "    \n",
    "    current_loss = current_loss / DATA_LENGTH\n",
    "    if current_loss < min_loss:\n",
    "        print('---|--- best model so far found: %f' % current_loss)\n",
    "        min_loss = current_loss\n",
    "        is_best = True\n",
    "    else:\n",
    "        print('---|--- model is worse: %f' % current_loss)\n",
    "    \n",
    "    save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'min_loss': min_loss,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, filepath='model_checkpoints/checkpoint.pth.tar')\n",
    "    \n",
    "    losses.append(current_loss)\n",
    "    print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
